{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3560e41-8649-42d0-af76-369aae1e5ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: gensim in c:\\python311\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python311\\lib\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\python311\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\python311\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# This notebook demonstrates how to train a word2vec model and get similar words for a list of seed words\n",
    "# Install necessary Python libraries\n",
    "!pip install nltk gensim pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac88cf10-0154-443b-be10-979178b13cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\018850882\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, string\n",
    "# Download NTLK components\n",
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a892fff-c32d-4cbc-bed2-a35cd7edea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk objects necessary for pre-processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Get NLTK stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Generate a set of punctuations, excluding \"-\" and \"_\"\n",
    "def gen_puncs():\n",
    "    puncs = string.punctuation\n",
    "    puncs = puncs.replace(\"-\", \"\")\n",
    "    puncs = puncs.replace(\"_\", \"\")\n",
    "    puncs_set = set(puncs)\n",
    "    return puncs_set\n",
    "puncs_set = gen_puncs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121220fa-b472-41db-a3a2-ce0f24b5cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the phraser model and word2vec model\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f66416-db9e-49b3-bc9c-4f8525cfd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize a doc into sentences and lemmatize them\n",
    "# Return a list of tokenized sentences, where each sentence is a list of lemmatized tokens\n",
    "def get_tokenized_lemmatized_sents(text):\n",
    "    # Define a function to lemmatize tokens\n",
    "    def lemm_tokens_nltk(tokenized_sents):\n",
    "        # Get the part of speech of a word\n",
    "        def get_wordnet_pos(treebank_tag):\n",
    "            if treebank_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif treebank_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif treebank_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif treebank_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return wordnet.NOUN\n",
    "    \n",
    "        tokenized_lemm_sents = []\n",
    "        for tokenized_sent in tokenized_sents:\n",
    "            word_pos = pos_tag(tokenized_sent)\n",
    "            lemm_words = [wnl.lemmatize(sw[0], get_wordnet_pos(sw[1])) for sw in word_pos]\n",
    "            tokenized_lemm_sents.append(lemm_words)\n",
    "        return tokenized_lemm_sents\n",
    "    \n",
    "    sents = sent_tokenize(text)\n",
    "    tokenized_sents = [word_tokenize(s) for s in sents]\n",
    "    # To lower cases so that proper nouns are handled properly\n",
    "    tokenized_sents = [[t.lower() for t in s] for s in tokenized_sents] \n",
    "    lemm_sents = lemm_tokens_nltk(tokenized_sents)\n",
    "    return lemm_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c81c7a-57b2-4e0c-be2e-88ac6cdb4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert all docs into a list of tokenized sentences, where each sentence is a list of lemmatized tokens \n",
    "def get_unigram_sents(docs):\n",
    "    tokenized_sents_unigram = []\n",
    "    for doc in docs:\n",
    "        lemm_sents = get_tokenized_lemmatized_sents(doc)\n",
    "        tokenized_sents_unigram += lemm_sents\n",
    "    return tokenized_sents_unigram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0374ce1a-285c-40cb-8a13-4da97f8c5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to identify and join two-word phrases by using the Bigram model\n",
    "# Take a list of tokenized sentences and output a list of tokenized sentences where some words are now joined into phrases\n",
    "def get_bigram_sents(tokenized_sents_unigram, bigram_model):\n",
    "    tokenized_sents_bigram = bigram_model[tokenized_sents_unigram]\n",
    "    return tokenized_sents_bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe89340e-a347-46df-b288-4bec3dacdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to identify and join three-word phrases by using the Trigram model\n",
    "# Take a list of tokenized sentences with two-word phrases and output a list of tokenized sentences \n",
    "# where some words are now joined into three-word phrases\n",
    "def get_trigram_sents(tokenized_sents_bigram, trigram_mod):\n",
    "    # sent_tokens is a list of tokens, already tokenized\n",
    "    tokenized_sents_with_trigrams = trigram_mod[tokenized_sents_bigram]\n",
    "    return tokenized_sents_with_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c710a477-7c4e-40d3-a78c-61cb3adb78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to screen words\n",
    "def is_valid_word(w):\n",
    "    if len(w)<2:  #Remove single-letter words\n",
    "        return False\n",
    "    if w in stop_words: # Remove stopword\n",
    "        return False\n",
    "    if any(map(str.isdigit, w)): # Remove words containing digits\n",
    "        return False\n",
    "    if any(char in puncs_set for char in w): # Remove words containing punctuations (excluding \"_\" and \"-\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Make sure that the ngram is a valid phrase\n",
    "def is_valid_ngram(ngram):\n",
    "    tokens=ngram.split(\"_\")\n",
    "    for t in tokens:\n",
    "        if not is_valid_word(t): # dropped of a stopword\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Break invalid phrases, e.g., converting \"the_people\" to \" the people\"\n",
    "def break_invalid_phrases(tokenized_sent):\n",
    "    tokens = []\n",
    "    for tok in tokenized_sent:\n",
    "        if (\"_\" in tok) and (not is_valid_ngram(tok)):\n",
    "            tokens += tok.split(\"_\")\n",
    "        else:\n",
    "            tokens.append(tok)\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3915e874-b5ac-4aab-bb5d-97e2e4089fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate the final output for training the word2vec model\n",
    "# The output is a list of tokenized sentences, where the tokens are lemmatized and phrased, \n",
    "# and certain tokens (e.g., punctuations, numbers, and stop words) are removed    \n",
    "def get_phrased_sents(docs, min_count=1, threshold=5):   \n",
    "    tokenized_sents_unigram = get_unigram_sents(docs)\n",
    "    # Train a bigram model\n",
    "    bigram = Phrases(tokenized_sents_unigram, min_count=min_count, threshold=threshold)\n",
    "    bigram_mod = Phraser(bigram) \n",
    "    # Generate tokenized sentences with bigrams\n",
    "    tokenized_sents_bigram = get_bigram_sents(tokenized_sents_unigram, bigram_mod)\n",
    "    # Feed tokenized sentences with bigrams to the phraser model to identify trigrams\n",
    "    trigram = Phrases(tokenized_sents_bigram, min_count=min_count, threshold=threshold)\n",
    "    trigram_mod = Phraser(trigram)\n",
    "    tokenized_sents_trigram = get_trigram_sents(tokenized_sents_bigram, trigram_mod)\n",
    "    # break invalid phrases\n",
    "    tokenized_sents_trigram  = [break_invalid_phrases(s) for s in tokenized_sents_trigram]\n",
    "    # Remove stopwords, numbers, etc., for faster training\n",
    "    tokenized_sents_trigram  = [[t for t in s if is_valid_word(t)] for s in tokenized_sents_trigram ]\n",
    "    return tokenized_sents_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e40c3b5-f712-409a-879b-8b52566cfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train a word2vec model\n",
    "def train_w2v_model(sents, vector_size=100, window=5, min_count=5, workers=3, epochs=3):    \n",
    "    w2v_model = Word2Vec(\n",
    "        sents,\n",
    "        vector_size = vector_size,\n",
    "        window = window,\n",
    "        min_count = min_count,\n",
    "        workers = workers,\n",
    "        epochs = epochs\n",
    "    )\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54df93f-c548-4b79-b974-2232dfb120ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the most similar words for a given word\n",
    "# Return a dataframe for all words which have an absolute cosine similarity score indicated by min_score. \n",
    "# The columns of the dataframe are similar word (\"SimWord\"), its cosine similarity score with the lookup word (\"SimScore\"),\n",
    "# and how many times the similar word appears in the corpus (\"SimWordFreq\").\n",
    "def get_most_similar_words(w2v_model, lookup_word, min_score=0.5):\n",
    "    voca_len = len(w2v_model.wv)\n",
    "    # print(list(w2v_model.wv.key_to_index))\n",
    "    all_similar_words = w2v_model.wv.most_similar(positive=[lookup_word], topn=voca_len)\n",
    "    # Then screen the words based on their cosine similarity scores with the lookup word\n",
    "    top_words = [[word, score, w2v_model.wv.get_vecattr(word,\"count\")] for word, score in all_similar_words if abs(score)>=min_score]\n",
    "    df = pd.DataFrame(top_words, columns=[\"SimWord\", \"SimScore\", \"SimWordFreq\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f6eecb-c0ba-4b2e-9f45-be32ac6348af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small sample of HC disclosures\n",
    "docs = [\n",
    "    \"The sustainability of Abbotts business depends on attracting, engaging and developing talented people with diverse backgrounds who share Abbotts mission to help people live their healthiest possible lives. Abbott provides its employees opportunities to grow and develop their careers, market competitive compensation and benefit programs, and the satisfaction of being part of a global company dedicated to improving health in more than 160 countries. As of December 31, 2020, Abbott employed approximately 109,000 people, 70% of whom were employed outside of the U.S. Women represented 47% of Abbotts U.S. workforce, 45% of its global workforce, and 39% of its managers.The health, safety and wellness of its employees is an Abbott priority embedded at every level of its business.  Abbotts integrated Environmental, Health and Safety organization governs health, safety and wellness at Abbotts facilities. Abbott also maintains global policies and standards for managing employee health and safety. Abbott takes a holistic approach to employee well-being. Abbotts global wellness programs are designed to meet the unique needs of employees across businesses and geographies and offer a wide range of programs, including supporting the mental, financial and physical health of employees and their families. For example, for over 20 years, Abbott has annually offered Exercise Across Abbott, which is a four-week physical wellness program that encourages employees to team up with colleagues and track how many minutes they exercise each day. Over 22,000 Abbott employees across 72 countries took part in 2020. During the COVID-19 pandemic, Abbott has taken aggressive steps to limit exposure and enhance the safety of facilities for its employees, including implementing mandatory temperature screening and social distancing, providing and requiring the use of personal protective equipment, and at most U.S. facilities, onsite COVID-19 testing. Abbott has an integrated global talent management process that is designed to identify and assess talent across the organization and provide equal and consistent opportunities for employees to develop their skills. All levels of employees participate in Abbotts annual performance management process to create development plans that support their particular career objectives, and Abbott provides a broad range of training, mentoring and other development opportunities to help its employees meet these objectives. The board of directors conducts an annual Talent Management Review, focusing on development of talent, diversity, and succession planning for critical positions. Similar reviews take place at every level of Abbott to develop talent and diversity across the organization. Abbott is committed to developing a workplace that is inclusive for all. Abbott ties executive compensation to human capital management, including diversity outcomes, to sustain an inclusive culture and the fair and balanced treatment of Abbotts employees. Abbotts employee networks play an important role in building an inclusive culture across all Abbott operations.  A member of Abbotts senior management serves as a sponsor for each of these networks, helping to align their objectives with Abbotts business strategies. Abbott has ten such networks, which are: Advancing Professionals Network (supporting early career employees), Asian Leadership and Cultural Network, Black Business Network, Flex Network (employees with part-time and flexible schedules), LA VOICE Network (supporting Hispanic and Latino employees), People with Disabilities Network, PRIDE (supporting LGBTQ employees), Veterans Network, Women Leaders of Abbott, and Women in STEM. Abbott offers professional development programs, which provide recent college graduates the opportunity to rotate through different areas of Abbott, often with the chance to work outside their home country. In 2020, 52% of the participants were women. Also, Abbott hosts hundreds of college students for paid internships. In 2020, 55% of the U.S. interns were women and 39% were minorities. Further, Abbott has operated a STEM internship program for high school students in the U.S. since 2012. The programs objective is to increase the number of students pursuing STEM-related careers and contribute to a more diverse talent pipeline for Abbott. In 2020, 58% of the STEM interns were women and 71% were minorities. Abbott is committed to building, retaining, and motivating a diverse talent pipeline that can meet the current and future needs of its businesses. To that end, Abbott provides market competitive compensation, healthcare benefits, pension and/or retirement savings plans, and several programs to facilitate employees building an ownership stake in Abbott, including a global long-term incentive program for employees generally beginning at the manager level. Abbott also has procedures and processes focused on providing employees equitable compensation, regardless of race or gender or other personal characteristics.\",\n",
    "    \"We have a global and varied workforce, with major employee centers in the U.S., Canada, U.K. and Romania. As of the end of 2020, we employed approximately 17,000 employees within our business globally with approximately 10,000 within our North America segment and 7,000 within our Europe segment. Of the 17,000 employees, approximately 660 of our employees are in our Global Business Centers based in Milwaukee, Wisconsin and Bucharest, Romania. As of the end of 2020, approximately 33% and 29% of our North America and Europe workforces, respectively, are represented by trade unions or councils, which are subject to collective bargaining agreements, which come due for renegotiation from time to time. The Company strives to be a provider of meaningful experiences for its employees and a safe and healthy workplace for all employees. We believe that building a strong and diverse workforce is a significant contributor to our success as a business and to deliver on our purpose, and that we value and respect our differences. We believe that diversity with inclusion is the key to collaboration and a winning team culture. A significant component of the revitalization plan announced in October 2019 was the launch of a refreshed purpose (uniting people to celebrate all life’s moments), ambition (first choice for our people, consumers and customers) and shared company values (the first of which is Putting People First), all designed with a purpose of shifting the culture of the organization to drive stronger employee engagement and business engagement. With the overarching goals described in the preceding paragraph as guides, the leadership team and the chief people and diversity officers for the North America and Europe business units are tasked with managing all employment-related matters including recruitment, retention, leadership and development, compensation planning, succession planning, performance management, and diversity and inclusion. The Compensation Human Resource Committee of the Board of Directors is responsible for establishing and reviewing the overall compensation philosophy of the Company and providing oversight on certain human capital matters, including the Company’s talent retention and development, leadership development, talent pipeline, programs and systems for performance management and diversity and inclusion initiatives. The Audit Committee oversees the Company’s risk management program to identify and mitigate potential risks, including human capital issues. The Board of Directors then receives regular reports and recommendations from management and the board committees to help guide the Company’s strategy on retaining and developing a diverse and talented workforce. In North America, we promote and maintain employee resource groups for a number of different communities in our employee population - by race/ethnicity, by gender, LGBTQ+, early professionals, young families, and veterans, amongst others. We encourage participation in these groups as we believe it provides an open forum for individual employees who may share similar concerns or experiences. We also promote and emphasize leadership and development opportunities for our employees which includes our First Choice Learning Center, in-person and online training programs, and experiential training opportunities to encourage and promote employee health and safety, assist in building core competencies, learning best practices and developing leadership capabilities. As we work to a more diverse workforce and management team, the Company has developed programs to encourage the recruitment, retention and training of diverse leaders and working to ensure we have a highly skilled and diverse workforce. We track and monitor our progress on metrics of gender and race, particularly in the U.S., though data on race is not tracked in all jurisdictions. We aim to ensure that our employees have a healthy and safe work environment. Our supply chain has adopted and implemented a framework we call world class supply chain 2.0 at many of our brewery and other locations. As part of that framework, the Company's environment, health and safety policy guides the Company’s efforts in maintaining safe and healthy workplaces where we take a proactive approach to the identification and control of environment, health and safety risks. We work to improve our Environment, Health and Safety (EHS) performance through methodologies that aim to prevent workplace injuries and illness, and reduce environmental impacts of our operations. Our safety focus was evident during our response to the coronavirus pandemic where we implemented additional health and safety measures in the breweries and our distribution centers, ensuring these federally designated essential operations could continue to operate and we could protect our employees. We enhanced our cleaning protocols at the majority of our facilities including enhanced sanitization, social distancing, temperature screenings, cloth facemasks and hand sanitizers, instituted a paid leave coronavirus policy and program, adopted a voluntary unpaid leave program, and expanded access to virtual healthcare, remote fitness and wellness support and to our employee assistance program.\",\n",
    "    \"At RPM, we understand that our company is only as strong as the team behind it. With the consistent support and dedication of leadership at all levels, we foster an environment that supports our associates as individuals and helps them thrive. Incorporating sustainable best practices in professional development, benefits, health and safety, and community involvement ensures that we can continue to hire the best associates and retain them throughout the course of their careers. It is critical to our long-term success to develop our internal talent.   Our Global Organizational Leadership Development (GOLD) Team is charged with creating a leadership-led learning culture across RPM.  The GOLD Team has developed several training programs to support development which include Leaders of the Future, RPM University, Strategic Leader Staff Rides, and partnering with the Center for Creative Leadership.  Since the inception of these programs the Company has seen many participants advance their careers, and the retention of participants has been greater than 90%. Our leadership has long understood that to attract and retain top talent, and to share the benefits of a successful business, we must maintain a premium benefits program for its associates. For U.S. associates, we offer an attractive benefits package, including defined benefit pension plans, medical, telehealth, tuition reimbursement and an employer-matched 401(k).  We also offer an Employee Assistance Program (EAP) which focuses on behavioral health and also provides resources for financial and legal matters. Mental health support has been key to employees during the Covid pandemic.  Employees can get this support through the EAP as well as through telehealth and we have seen an increase in the use of such services. Similar ancillary benefits are offered to our Canadian associates, and employees of our other foreign subsidiaries receive benefits coverage, to the extent deemed appropriate, through plans that meet local requirements. At RPM, we have built our workforce, in part, through our commitment to create a diverse and inclusive culture. While there are many examples in our corporate practices, policies, and internal and external programs, we are particularly proud of our Tremco/WTI partnership with the Department of Corrections.  This program provides roof training to designated inmates while still incarcerated.  Upon release, WTI guarantees employment opportunities to qualified participants within a pay range of $16 to $23 per hour, plus benefits, depending on roof competency. We follow many best practices to ensure our associates come to work feeling empowered to safely do their jobs.   As part of our environmental management system, we continuously educate and train to institutionalize our health and safety values, set and monitor health and safety objectives, conduct regular risk assessments and process hazard and root cause analysis, and actively enforce accident prevention and reporting policies. As of May 31, 2021, we employed 15,490 persons, of whom approximately 648 were represented by unions under contracts which expire at varying times in the future.  We believe that all relations with employees and their unions are good.\",\n",
    "    \"We believe that, beyond being essential to our operations, our people have inestimable worth independent of our business. As outlined in our Human Rights Policy (see, www.american-vanguard.com under ESG tab), we believe that it is fundamental to our corporate responsibility and, indeed, to our humanity, that we recognize, respect and nurture the freedom and dignity of all persons. Accordingly, we have insinuated that belief throughout the fabric of our operations in our approach toward our employees. Indeed, the first two core values underlying our commitment to sustainability (see, Update to Corporate Sustainability Report, www.american-vanguard.com under ESG tab) are “Safety First” – which is a culture that begins with highly-regulated manufacturing plants, continues into the design of science-backed products and extends into market-leading delivery systems – and “Making a Difference” – under which, by rewarding achievement and giving our employees a voice, we attract diverse employees who want to make a difference in their careers, in the company and in the communities that we serve. Our Human Capital program consists of the following elements: Board Oversight – through our Nominating and Corporate Governance Committee (“N&CG”), our board of directors oversees human capital-related risks and opportunities. At least annually, the N&CG Committee requires that management update succession planning for key executives, including with respect to planning for the future with a commitment toward diversity, equity and inclusion. Strategy – the Company’s human capital strategy has two primary elements: giving our employees a voice and providing them with generous benefits (including an unrivalled health benefits plan and awards of common stock to the entire workforce). As we have covered in our Update to Corporate Sustainability Report, our company is a destination for highly qualified employees who are drawn to a workplace where they can make a difference. Our managerial approach is that our functions work in a collaborative manner – cutting across departmental lines to arrive at better solutions with a high level of efficiency. This strategy has enabled the Company to maximize retention, even in an increasingly competitive employment market. Compensation – as mentioned in our Strategy above, compensation is an essential element of our human capital approach. During the pandemic in the midst of the so-called “Great Resignation” that affected many industries, we took measures to incentivize our workforce to remain with us, including across-the-board wage increases in certain of our manufacturing facilities. To the extent that our highly skilled personnel are being recruited by other companies, we endeavor to keep an open conversation on their needs and, where appropriate, have increased their total compensation (through a combination of wage, stock and/or vacation) to retain them. Voice – our management style is to solicit good ideas from employees, involve them in implementation and give them recognition for ideas that succeed. For example, personnel from virtually any department (be it sales, technology, product development or otherwise) can submit ideas to our Innovation Review Committee (“IRC”) for consideration and potential funding. The IRC continues to be a source of new product ideas that has enabled us to launch several new formulations and other solutions on an annual basis. Similarly, our Beekeeper platform is a company-only social media channel on which employees anywhere in the world can report on their accomplishments, commendations of others and local developments. Diversity, Equity and Inclusion (DEI) – the Company continues to expand its DEI program. In 2021, with the retirement of Lawrence Clark from our board of directors, the Company called upon the Latino Corporate Directors Association to help recruit Marisol Angelini as a new director. With Ms. Angelini’s addition to the board, three of nine members (33%) of our board are female and three of nine (again, 33%) are from underrepresented groups (LGBTQ, Middle Eastern and Latinx). Based upon the Company’s most current EEO-1 (“Equal Employment Opportunity”) Report, representation of African Americans in our domestic workforce exceeds the prevalence of that group in the national population, while representation of Hispanic personnel is slightly below the national average. Nevertheless, during 2022, the Company is working on a plan to advance its commitment to DEI throughout the workforce. The Company employed 804 employees as of December 31, 2021, and 771 employees as of December 31, 2020. From time to time, due to the seasonality of its business, AVD uses temporary contract personnel to perform certain duties primarily related to packaging of its products. None of the Company’s employees are subject to a collective bargaining agreement. The Company believes it maintains positive relations with its employees.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a20b840-6327-4d74-83e7-e7f6a71eced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate phrased and tokenized sentences\n",
    "phrased_sents = get_phrased_sents(docs, min_count=2, threshold=10)\n",
    "# Train a w2v model (using a small vector_size due to the small sample size)\n",
    "w2v_mod = train_w2v_model(phrased_sents, vector_size=30, window=5, min_count=3, workers=5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f71b390-5f64-488b-98b9-a9532e1f06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee\n",
      "        SimWord  SimScore  SimWordFreq\n",
      "0         level  0.533215            6\n",
      "1     diversity  0.472661            9\n",
      "2  compensation  0.455126           10\n",
      "3        global  0.423858            9\n",
      "4     committee  0.415127            5\n",
      "diversity\n",
      "    SimWord  SimScore  SimWordFreq\n",
      "0    people  0.589679            9\n",
      "1    global  0.497653            9\n",
      "2  employee  0.472661           52\n",
      "3    report  0.462358            5\n",
      "4  pandemic  0.405816            4\n",
      "talent\n",
      "             SimWord  SimScore  SimWordFreq\n",
      "0      approximately  0.492184            6\n",
      "1        competitive  0.490279            3\n",
      "2              track  0.480771            3\n",
      "3  inclusive_culture  0.391258            3\n",
      "4             strong  0.315198            3\n",
      "career\n",
      "   SimWord  SimScore  SimWordFreq\n",
      "0    first  0.532908            6\n",
      "1    voice  0.400650            4\n",
      "2   leader  0.379823            4\n",
      "3   matter  0.377745            3\n",
      "4  country  0.372866            3\n",
      "gender\n",
      "      SimWord  SimScore  SimWordFreq\n",
      "0  leadership  0.538074           10\n",
      "1      employ  0.499631            5\n",
      "2     abbotts  0.464496           11\n",
      "3       build  0.462411            5\n",
      "4        help  0.442155            6\n"
     ]
    }
   ],
   "source": [
    "# Get the most similar words for each seed word\n",
    "seed_words = [\"employee\", \"diversity\", \"talent\", \"career\", \"gender\"]\n",
    "for seed_word in seed_words:\n",
    "    df = get_most_similar_words(w2v_mod, seed_word, min_score=0.3)\n",
    "    print(seed_word)\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
